# 日志收集方案

## 版本信息
- 版本号: v1.0.0
- 更新日期: 2024-03-21
- 状态: [✅] 已完成

## 一、收集范围
### 1.1 应用日志
1. 业务日志
   - 应用运行日志
   - 业务操作日志
   - 接口调用日志
   - 错误异常日志

2. 中间件日志
   - Web服务器日志
   - 数据库日志
   - 缓存服务日志
   - 消息队列日志

3. 容器日志
   - Docker容器日志
   - K8s集群日志
   - Service Mesh日志
   - 容器运行时日志

### 1.2 系统日志
1. 操作系统日志
   ```bash
   # Linux系统日志
   /var/log/messages    # 系统日志
   /var/log/secure      # 安全日志
   /var/log/cron        # 定时任务日志
   /var/log/dmesg       # 内核日志
   /var/log/audit       # 审计日志
   ```

2. 网络设备日志
   - 防火墙日志
   - 路由器日志
   - 交换机日志
   - 负载均衡器日志

## 二、收集方案
### 2.1 Agent部署
1. 主机Agent
   ```yaml
   # Filebeat配置
   filebeat.inputs:
   - type: log
     enabled: true
     paths:
       - /var/log/*.log
     fields:
       type: system
       env: prod
     
   - type: log
     enabled: true
     paths:
       - /opt/apps/*/logs/*.log
     fields:
       type: application
       env: prod
     multiline:
       pattern: '^\d{4}-\d{2}-\d{2}'
       negate: true
       match: after
   
   output.kafka:
     hosts: ["kafka1:9092", "kafka2:9092", "kafka3:9092"]
     topic: "logs-%{[fields.type]}"
     compression: gzip
   ```

2. 容器Agent
   ```yaml
   # Fluentd配置
   <source>
     @type forward
     port 24224
     bind 0.0.0.0
   </source>
   
   <filter **>
     @type record_transformer
     <record>
       hostname "#{Socket.gethostname}"
       tag ${tag}
       pod_name ${record["kubernetes"]["pod_name"]}
       namespace ${record["kubernetes"]["namespace_name"]}
     </record>
   </filter>
   
   <match **>
     @type kafka2
     brokers kafka1:9092,kafka2:9092,kafka3:9092
     default_topic logs
     <format>
       @type json
     </format>
     <buffer>
       @type memory
       flush_interval 1s
     </buffer>
   </match>
   ```

### 2.2 采集策略
1. 文件采集
   ```yaml
   # 采集配置
   collection:
     # 文件监控
     file_monitor:
       scan_frequency: 10s
       close_inactive: 5m
       ignore_older: 24h
       clean_inactive: 72h
     
     # 多行处理
     multiline:
       patterns:
         - '^[0-9]{4}-[0-9]{2}-[0-9]{2}'  # 时间戳开头
         - '^\[ERROR\]'                     # 错误日志
         - '^Exception in thread'           # 异常堆栈
       max_lines: 500
       timeout: 5s
     
     # 字符编码
     encoding:
       - UTF-8
       - GBK
       - ISO-8859-1
   ```

2. 网络采集
   ```yaml
   # 网络采集配置
   network:
     # TCP采集
     tcp:
       port: 5140
       max_connections: 2000
       timeout: 300s
     
     # UDP采集
     udp:
       port: 5140
       workers: 4
       queue_size: 10000
     
     # HTTP采集
     http:
       port: 8080
       max_body_size: 10m
       compression: true
   ```

## 三、数据处理
### 3.1 数据清洗
1. 字段提取
   ```ruby
   # Logstash处理规则
   filter {
     grok {
       match => {
         "message" => "%{TIMESTAMP_ISO8601:timestamp}|%{LOGLEVEL:level}|%{DATA:thread}|%{DATA:class}|%{GREEDYDATA:msg}"
       }
     }
     date {
       match => [ "timestamp", "yyyy-MM-dd HH:mm:ss.SSS" ]
       target => "@timestamp"
     }
     mutate {
       remove_field => [ "message" ]
     }
   }
   ```

2. 数据转换
   ```ruby
   # 数据处理规则
   filter {
     # 类型转换
     mutate {
       convert => {
         "response_time" => "integer"
         "status_code" => "integer"
         "bytes" => "integer"
       }
     }
     
     # 字段处理
     mutate {
       gsub => [
         "user_agent", "Mozilla\/[0-9.]+", "Mozilla",
         "path", "token=[^&]+", "token=***"
       ]
     }
     
     # 字段添加
     mutate {
       add_field => {
         "environment" => "production"
         "service_name" => "user-service"
       }
     }
   }
   ```

### 3.2 数据加工
1. 数据脱敏
   ```python
   def mask_sensitive_data(data):
       """
       敏感数据脱敏
       """
       # 手机号脱敏
       if 'phone' in data:
           data['phone'] = re.sub(r'(\d{3})\d{4}(\d{4})', r'\1****\2', data['phone'])
       
       # 身份证脱敏
       if 'id_card' in data:
           data['id_card'] = re.sub(r'(\d{6})\d{8}(\d{4})', r'\1********\2', data['id_card'])
       
       # 邮箱脱敏
       if 'email' in data:
           data['email'] = re.sub(r'([\w.]{2})[\w.]+(@[\w.]+)', r'\1***\2', data['email'])
       
       return data
   ```

2. 数据富化
   ```python
   def enrich_log_data(data):
       """
       日志数据富化
       """
       # IP地址信息
       if 'ip' in data:
           ip_info = get_ip_info(data['ip'])
           data.update({
               'country': ip_info['country'],
               'province': ip_info['province'],
               'city': ip_info['city'],
               'isp': ip_info['isp']
           })
       
       # 设备信息
       if 'user_agent' in data:
           ua_info = parse_user_agent(data['user_agent'])
           data.update({
               'browser': ua_info['browser'],
               'os': ua_info['os'],
               'device': ua_info['device']
           })
       
       # 业务信息
       if 'user_id' in data:
           user_info = get_user_info(data['user_id'])
           data.update({
               'user_type': user_info['type'],
               'user_level': user_info['level'],
               'register_time': user_info['register_time']
           })
       
       return data
   ```

## 四、质量控制
### 4.1 数据校验
1. 格式校验
   ```python
   def validate_log_format(log):
       """
       日志格式校验
       """
       required_fields = ['timestamp', 'level', 'service', 'message']
       
       # 必填字段检查
       for field in required_fields:
           if field not in log:
               raise ValueError(f"Missing required field: {field}")
       
       # 时间格式检查
       try:
           datetime.strptime(log['timestamp'], '%Y-%m-%d %H:%M:%S.%f')
       except ValueError:
           raise ValueError("Invalid timestamp format")
       
       # 日志级别检查
       valid_levels = ['DEBUG', 'INFO', 'WARN', 'ERROR', 'FATAL']
       if log['level'] not in valid_levels:
           raise ValueError("Invalid log level")
       
       return True
   ```

2. 内容校验
   ```python
   def validate_log_content(log):
       """
       日志内容校验
       """
       # 内容长度检查
       if len(log['message']) > 10000:
           raise ValueError("Message too long")
       
       # 敏感信息检查
       sensitive_patterns = [
           r'\d{18}',  # 身份证
           r'\d{16}',  # 银行卡
           r'\d{11}',  # 手机号
           r'password=[\w\W]+'  # 密码
       ]
       
       for pattern in sensitive_patterns:
           if re.search(pattern, log['message']):
               raise ValueError("Contains sensitive information")
       
       return True
   ```

### 4.2 质量监控
1. 采集监控
   ```yaml
   # 监控指标
   metrics:
     # 采集状态
     collection:
       - name: log_collection_total
         type: counter
         labels: [source, type]
       - name: log_collection_errors
         type: counter
         labels: [source, error_type]
       - name: log_collection_delay
         type: gauge
         labels: [source]
     
     # 处理状态
     processing:
       - name: log_processing_total
         type: counter
         labels: [processor]
       - name: log_processing_errors
         type: counter
         labels: [processor, error_type]
       - name: log_processing_time
         type: histogram
         labels: [processor]
   ```

2. 告警规则
   ```yaml
   # 告警配置
   alerts:
     # 采集异常
     collection:
       - name: high_collection_error_rate
         expr: rate(log_collection_errors[5m]) / rate(log_collection_total[5m]) > 0.01
         for: 5m
         labels:
           severity: critical
         annotations:
           summary: High collection error rate
     
     # 处理延迟
     processing:
       - name: high_processing_delay
         expr: log_processing_time_bucket{quantile="0.95"} > 1000
         for: 5m
         labels:
           severity: warning
         annotations:
           summary: High processing delay
   ```

## 相关文档
- [日志架构设计](01_日志架构设计.md)
- [日志分析工具](03_日志分析工具.md)
- [日志最佳实践](04_日志最佳实践.md)

## 更新记录
- 2024-03-21: 创建日志收集方案文档 